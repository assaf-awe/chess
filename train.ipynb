{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c61d6e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/assaf/jupyter/chess\n"
     ]
    }
   ],
   "source": [
    "%cd /home/assaf/jupyter/chess\n",
    "%reset -f\n",
    "\n",
    "import chess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from chess_utils import matrix_to_board\n",
    "\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62b5e7e",
   "metadata": {},
   "source": [
    "### Build a DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a6e21a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080598, 10021)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            self.states_df = pickle.load(f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # display(self.states_df.iloc[idx])\n",
    "        if self.states_df.iloc[idx].winner == 'black':\n",
    "            winner = -1 \n",
    "        elif self.states_df.iloc[idx].winner == 'white':\n",
    "            winner = 1 \n",
    "        else:\n",
    "            winner = 0\n",
    "        if self.states_df.iloc[idx].turn %2:   #white turn \n",
    "            brd_state =  self.states_df.iloc[idx].matrix\n",
    "        else:\n",
    "            brd_state =  np.flipud(-self.states_df.iloc[idx].matrix).copy() \n",
    "            winner = -winner\n",
    "        n = torch.tensor(brd_state+7).unsqueeze(0).to(torch.int64)\n",
    "        brd_state3d = torch.zeros(15, 8, 8, dtype=torch.float32)\n",
    "        brd_state3d.scatter_(0, n, 1.0)\n",
    "        brd_state3d = brd_state3d[[0,1,2,3,4,5,6,8,9,10,11,12,13,14],:,:]\n",
    "        steps = self.states_df.iloc[idx].turns-self.states_df.iloc[idx].turn \n",
    "        result = torch.tensor((winner, steps), dtype=torch.float32)\n",
    "        return brd_state3d, result\n",
    "        # return torch.tensor(brd_state3d, dtype=torch.float32).unsqueeze(0), result\n",
    "\n",
    "train_ds = ChessDataset(\"train_states_ds.pkl\")\n",
    "test_ds = ChessDataset(\"test_states_ds.pkl\")\n",
    "len(train_ds), len(test_ds)\n",
    "\n",
    "# train_ds[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "60778117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyResNet, self).__init__()\n",
    "        \n",
    "        do = 0.1\n",
    "\n",
    "        self.cnn_0 = nn.Conv2d(in_channels=14,  out_channels=64,  kernel_size=1, padding=0, stride=1) \n",
    "\n",
    "        self.cnn_1 = nn.Conv2d(in_channels=64,  out_channels=64,  kernel_size=5, padding=2, stride=1)\n",
    "        self.cnn_2 = nn.Conv2d(in_channels=64,  out_channels=64,  kernel_size=5, padding=2, stride=1)\n",
    "        self.cnn_3 = nn.Conv2d(in_channels=64,  out_channels=128, kernel_size=3, padding=1, stride=1) #here comes pooling 8->4\n",
    "        self.cnn_4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=1)\n",
    "        self.cnn_5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1) #here comes pooling 4->2\n",
    "        self.cnn_6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1)\n",
    "        self.cnn_7 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=1) #here comes pooling 2->1\n",
    "\n",
    "        self.ln2d_1 = nn.LayerNorm([64, 8, 8])\n",
    "        self.ln2d_2 = nn.LayerNorm([64, 8, 8])\n",
    "        self.ln2d_3 = nn.LayerNorm([128, 4, 4])\n",
    "        self.ln2d_4 = nn.LayerNorm([128, 4, 4])\n",
    "        self.ln2d_5 = nn.LayerNorm([256, 2, 2])\n",
    "        self.ln2d_6 = nn.LayerNorm([256, 2, 2])\n",
    "        self.ln2d_7 = nn.LayerNorm([512, 1, 1])\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.output_layer = nn.Linear(512, 2)\n",
    "        self.dropout = nn.Dropout(p=do)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_0(x)\n",
    "\n",
    "        x = torch.relu(self.cnn_1(x))\n",
    "        x = self.ln2d_1(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.cnn_2(x))\n",
    "        x = self.ln2d_2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.cnn_3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.ln2d_3(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.cnn_4(x))\n",
    "        x = self.ln2d_4(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.cnn_5(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.ln2d_5(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.cnn_6(x))\n",
    "        x = self.ln2d_6(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.cnn_7(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.ln2d_7(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.flatten(x,x.ndim-3)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "37713309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "0 [7.88316619e-01 7.88316619e-01 2.38591017e+03] 0.3007196015539544\n",
      "test-results 0 [7.51224475e-01 7.51224475e-01 2.69176157e+03] 0.3054585370721485\n",
      "1 [7.29955212e-01 7.29955212e-01 2.38502328e+03] 0.3715340950103554\n",
      "test-results 1 [7.12530010e-01 7.12530010e-01 2.69176157e+03] 0.36174034527492266\n",
      "2 [7.11603377e-01 7.11603377e-01 2.38505212e+03] 0.3962666967734532\n",
      "test-results 2 [6.87065000e-01 6.87065000e-01 2.69176157e+03] 0.37960283404849815\n",
      "3 [6.94440734e-01 6.94440734e-01 2.38506391e+03] 0.4174790255025458\n",
      "test-results 3 [7.03112608e-01 7.03112608e-01 2.69176157e+03] 0.41063766091208465\n",
      "4 [6.77811842e-01 6.77811842e-01 2.38504187e+03] 0.43643612148088373\n",
      "test-results 4 [7.08055680e-01 7.08055680e-01 2.69176157e+03] 0.3918770581778266\n",
      "5 [6.61607962e-01 6.61607962e-01 2.38499735e+03] 0.45513687791389584\n",
      "test-results 5 [7.10362957e-01 7.10362957e-01 2.69176157e+03] 0.43039616804710107\n",
      "6 [6.47051695e-01 6.47051695e-01 2.38492552e+03] 0.47168697332402987\n",
      "test-results 6 [7.22459090e-01 7.22459090e-01 2.69176157e+03] 0.43618401357149983\n",
      "7 [6.35154724e-01 6.35154724e-01 2.38498517e+03] 0.48519986155813727\n",
      "test-results 7 [7.21662849e-01 7.21662849e-01 2.69176157e+03] 0.43528589961081726\n",
      "8 [6.23196576e-01 6.23196576e-01 2.38504339e+03] 0.49783545777430643\n",
      "test-results 8 [7.51185531e-01 7.51185531e-01 2.69176157e+03] 0.4443668296577188\n",
      "9 [6.13847138e-01 6.13847138e-01 2.38500625e+03] 0.5048186282040129\n",
      "test-results 9 [7.31912424e-01 7.31912424e-01 2.69176157e+03] 0.43857898413332\n",
      "10 [6.05736042e-01 6.05736042e-01 2.38502350e+03] 0.511005017592111\n",
      "test-results 10 [7.50571543e-01 7.50571543e-01 2.69176157e+03] 0.43548548049096897\n",
      "11 [5.97612202e-01 5.97612202e-01 2.38513131e+03] 0.5193244851461876\n",
      "test-results 11 [7.43973389e-01 7.43973389e-01 2.69176157e+03] 0.4534477597046203\n",
      "12 [5.90440394e-01 5.90440394e-01 2.38509353e+03] 0.5261531115178818\n",
      "test-results 12 [7.53249541e-01 7.53249541e-01 2.69176157e+03] 0.44147290689551943\n",
      "13 [5.85068030e-01 5.85068030e-01 2.38513846e+03] 0.5297529701146958\n",
      "test-results 13 [7.77806670e-01 7.77806670e-01 2.69176157e+03] 0.4548448258656821\n",
      "14 [5.79074431e-01 5.79074431e-01 2.38528668e+03] 0.5370748418931\n",
      "test-results 14 [7.42235094e-01 7.42235094e-01 2.69176157e+03] 0.4534477597046203\n",
      "15 [5.74402614e-01 5.74402614e-01 2.38503881e+03] 0.5406312060544254\n",
      "test-results 15 [7.37503842e-01 7.37503842e-01 2.69176157e+03] 0.44506536273824965\n",
      "16 [5.70971433e-01 5.70971433e-01 2.38511210e+03] 0.5448770032889196\n",
      "test-results 16 [7.43945944e-01 7.43945944e-01 2.69176157e+03] 0.44666200977946313\n",
      "17 [5.66263408e-01 5.66263408e-01 2.38508731e+03] 0.5476541692655363\n",
      "test-results 17 [7.36905551e-01 7.36905551e-01 2.69176157e+03] 0.46901506835645146\n",
      "18 [5.62165804e-01 5.62165804e-01 2.38504588e+03] 0.5512429229000979\n",
      "test-results 18 [7.48566554e-01 7.48566554e-01 2.69176157e+03] 0.4667198882347071\n",
      "19 [5.59575192e-01 5.59575192e-01 2.38508585e+03] 0.5555266620889544\n",
      "test-results 19 [7.35941572e-01 7.35941572e-01 2.69176157e+03] 0.4600339287496258\n",
      "20 [5.56741666e-01 5.56741666e-01 2.38498815e+03] 0.555889424189199\n",
      "test-results 20 [7.40206948e-01 7.40206948e-01 2.69176157e+03] 0.4619299471110668\n",
      "21 [5.53199071e-01 5.53199071e-01 2.38514336e+03] 0.5590423080553545\n",
      "test-results 21 [7.25540493e-01 7.25540493e-01 2.69176157e+03] 0.45384692146492367\n",
      "22 [5.51254481e-01 5.51254481e-01 2.38498380e+03] 0.5618009657615506\n",
      "test-results 22 [7.39290497e-01 7.39290497e-01 2.69176157e+03] 0.45853707214848816\n",
      "23 [5.49079662e-01 5.49079662e-01 2.38507815e+03] 0.5638368755078207\n",
      "test-results 23 [7.57650189e-01 7.57650189e-01 2.69176157e+03] 0.47500249476100187\n",
      "24 [5.46404591e-01 5.46404591e-01 2.38507147e+03] 0.5662827434439079\n",
      "test-results 24 [7.55067667e-01 7.55067667e-01 2.69176157e+03] 0.47071150583774074\n",
      "25 [5.44192512e-01 5.44192512e-01 2.38505772e+03] 0.5671424526049466\n",
      "test-results 25 [7.57107508e-01 7.57107508e-01 2.69176157e+03] 0.46851611615607225\n",
      "26 [5.41709531e-01 5.41709531e-01 2.38510076e+03] 0.569361594228381\n",
      "test-results 26 [7.64268274e-01 7.64268274e-01 2.69176157e+03] 0.4794930645644147\n",
      "27 [5.40806100e-01 5.40806100e-01 2.38496331e+03] 0.5705748113544538\n",
      "test-results 27 [7.47225380e-01 7.47225380e-01 2.69176157e+03] 0.4735056381598643\n",
      "28 [5.38297876e-01 5.38297876e-01 2.38502107e+03] 0.5727772955345096\n",
      "test-results 28 [7.47963434e-01 7.47963434e-01 2.69176157e+03] 0.47360542859994015\n",
      "29 [5.36802069e-01 5.36802069e-01 2.38495982e+03] 0.5734047259017692\n",
      "test-results 29 [7.43552229e-01 7.43552229e-01 2.69176157e+03] 0.4672188404350863\n",
      "30 [5.34875861e-01 5.34875861e-01 2.38504798e+03] 0.5745078188188392\n",
      "test-results 30 [7.54106471e-01 7.54106471e-01 2.69176157e+03] 0.45803811994810895\n",
      "31 [5.33600128e-01 5.33600128e-01 2.38517954e+03] 0.576391035334139\n",
      "test-results 31 [7.51329412e-01 7.51329412e-01 2.69176157e+03] 0.46502345075341783\n",
      "32 [5.32300745e-01 5.32300745e-01 2.38507979e+03] 0.5763938115747022\n",
      "test-results 32 [7.54649183e-01 7.54649183e-01 2.69176157e+03] 0.45504440674583374\n",
      "33 [5.30901464e-01 5.30901464e-01 2.38494632e+03] 0.5782946109469016\n",
      "test-results 33 [7.48399505e-01 7.48399505e-01 2.69176157e+03] 0.4697136014369823\n",
      "34 [5.29805033e-01 5.29805033e-01 2.38501153e+03] 0.5796744025067602\n",
      "test-results 34 [7.55511190e-01 7.55511190e-01 2.69176157e+03] 0.46771779263546553\n",
      "35 [5.28436733e-01 5.28436733e-01 2.38510731e+03] 0.5810754785776024\n",
      "test-results 35 [7.49890713e-01 7.49890713e-01 2.69176157e+03] 0.4591358147889432\n",
      "36 [5.28042872e-01 5.28042872e-01 2.38509928e+03] 0.5808848433922699\n",
      "test-results 36 [7.43900660e-01 7.43900660e-01 2.69176157e+03] 0.4507534178225726\n",
      "37 [5.26941829e-01 5.26941829e-01 2.38519788e+03] 0.5828911399058669\n",
      "test-results 37 [7.61559637e-01 7.61559637e-01 2.69176157e+03] 0.48009180720486977\n",
      "38 [5.25089060e-01 5.25089060e-01 2.38498053e+03] 0.5839868295147687\n",
      "test-results 38 [7.53629423e-01 7.53629423e-01 2.69176157e+03] 0.47390479992016765\n",
      "39 [5.24451601e-01 5.24451601e-01 2.38517063e+03] 0.5840562355288461\n",
      "test-results 39 [7.56906409e-01 7.56906409e-01 2.69176157e+03] 0.46502345075341783\n",
      "40 [5.23817776e-01 5.23817776e-01 2.38505863e+03] 0.5848520911569335\n",
      "test-results 40 [7.74950099e-01 7.74950099e-01 2.69176157e+03] 0.4774972557628979\n",
      "41 [5.22645750e-01 5.22645750e-01 2.38507045e+03] 0.585796938361907\n",
      "test-results 41 [7.60906010e-01 7.60906010e-01 2.69176157e+03] 0.4598343478694741\n",
      "42 [5.21648828e-01 5.21648828e-01 2.38522412e+03] 0.5873451551825933\n",
      "test-results 42 [7.74983695e-01 7.74983695e-01 2.69176157e+03] 0.45793832950803315\n",
      "43 [5.21100803e-01 5.21100803e-01 2.38510987e+03] 0.5881243533673022\n",
      "test-results 43 [7.76010462e-01 7.76010462e-01 2.69176157e+03] 0.46662009779463126\n",
      "44 [5.19970826e-01 5.19970826e-01 2.38495999e+03] 0.5881576682540594\n",
      "test-results 44 [7.66569767e-01 7.66569767e-01 2.69176157e+03] 0.4643249176728869\n",
      "45 [5.19065697e-01 5.19065697e-01 2.38505882e+03] 0.5890988138049488\n",
      "test-results 45 [7.71790693e-01 7.71790693e-01 2.69176157e+03] 0.47220836243887837\n",
      "46 [5.17898544e-01 5.17898544e-01 2.38502743e+03] 0.5894088273344944\n",
      "test-results 46 [7.85803508e-01 7.85803508e-01 2.69176157e+03] 0.46681967867478297\n",
      "47 [5.18146659e-01 5.18146659e-01 2.38501283e+03] 0.5903805115315779\n",
      "test-results 47 [7.76101871e-01 7.76101871e-01 2.69176157e+03] 0.45993413830954993\n",
      "48 [5.17540212e-01 5.17540212e-01 2.38499055e+03] 0.5902546552927176\n",
      "test-results 48 [7.73863096e-01 7.73863096e-01 2.69176157e+03] 0.46442470811296277\n",
      "49 [5.16156845e-01 5.16156845e-01 2.38501556e+03] 0.5906877488205605\n",
      "test-results 49 [7.50268636e-01 7.50268636e-01 2.69176157e+03] 0.4573395868675781\n",
      "50 [5.16025336e-01 5.16025336e-01 2.38510654e+03] 0.5919657448931055\n",
      "test-results 50 [7.73056599e-01 7.73056599e-01 2.69176157e+03] 0.47101087715796824\n",
      "51 [5.14309028e-01 5.14309028e-01 2.38510458e+03] 0.5942598450117434\n",
      "test-results 51 [7.64147873e-01 7.64147873e-01 2.69176157e+03] 0.4808901307254765\n",
      "52 [5.13555199e-01 5.13555199e-01 2.38500993e+03] 0.5944440023024289\n",
      "test-results 52 [7.71485493e-01 7.71485493e-01 2.69176157e+03] 0.46392575591258356\n",
      "53 [5.12711094e-01 5.12711094e-01 2.38497724e+03] 0.5936314892309629\n",
      "test-results 53 [7.73832033e-01 7.73832033e-01 2.69176157e+03] 0.4593353956690949\n",
      "54 [5.12674563e-01 5.12674563e-01 2.38504754e+03] 0.5938841271222045\n",
      "test-results 54 [7.50756023e-01 7.50756023e-01 2.69176157e+03] 0.47150982935834745\n",
      "55 [5.12327200e-01 5.12327200e-01 2.38506273e+03] 0.5941959914787923\n",
      "test-results 55 [7.80053123e-01 7.80053123e-01 2.69176157e+03] 0.46711904999501047\n",
      "56 [5.10467049e-01 5.10467049e-01 2.38509099e+03] 0.5956609210825857\n",
      "test-results 56 [7.74668586e-01 7.74668586e-01 2.69176157e+03] 0.4853807005288893\n",
      "57 [5.10396394e-01 5.10396394e-01 2.38500496e+03] 0.5951001204888404\n",
      "test-results 57 [7.70423097e-01 7.70423097e-01 2.69176157e+03] 0.46562219339387284\n",
      "58 [5.10227215e-01 5.10227215e-01 2.38502715e+03] 0.5961208516025386\n",
      "test-results 58 [7.64146416e-01 7.64146416e-01 2.69176157e+03] 0.45773874862788144\n",
      "59 [5.09951542e-01 5.09951542e-01 2.38504558e+03] 0.5962050642329525\n",
      "test-results 59 [7.63456809e-01 7.63456809e-01 2.69176157e+03] 0.47500249476100187\n",
      "60 [5.08871453e-01 5.08871453e-01 2.38500036e+03] 0.5957062663451164\n",
      "test-results 60 [7.79681994e-01 7.79681994e-01 2.69176157e+03] 0.4701127631972857\n",
      "61 [5.09315476e-01 5.09315476e-01 2.38506220e+03] 0.5958210176217242\n",
      "test-results 61 [7.88764401e-01 7.88764401e-01 2.69176157e+03] 0.45254964574393775\n",
      "62 [5.08622091e-01 5.08622091e-01 2.38518849e+03] 0.5977708639105385\n",
      "test-results 62 [7.60881796e-01 7.60881796e-01 2.69176157e+03] 0.46831653527592054\n",
      "63 [5.07663900e-01 5.07663900e-01 2.38504672e+03] 0.59918026870307\n",
      "test-results 63 [7.85096112e-01 7.85096112e-01 2.69176157e+03] 0.4788943219239597\n",
      "64 [5.08409242e-01 5.08409242e-01 2.38515502e+03] 0.5977847451133539\n",
      "test-results 64 [7.77884751e-01 7.77884751e-01 2.69176157e+03] 0.4608322522702325\n",
      "65 [5.07530293e-01 5.07530293e-01 2.38502392e+03] 0.5996327959148545\n",
      "test-results 65 [7.88628082e-01 7.88628082e-01 2.69176157e+03] 0.48128929248577984\n",
      "66 [5.06987313e-01 5.06987313e-01 2.38505176e+03] 0.5988073270540941\n",
      "test-results 66 [7.90227111e-01 7.90227111e-01 2.69176157e+03] 0.45963476698932243\n",
      "67 [5.06502687e-01 5.06502687e-01 2.38524715e+03] 0.600226911395357\n",
      "test-results 67 [7.90783613e-01 7.90783613e-01 2.69176157e+03] 0.474303961680471\n",
      "68 [5.05744629e-01 5.05744629e-01 2.38500652e+03] 0.6007321871778404\n",
      "test-results 68 [7.82054506e-01 7.82054506e-01 2.69176157e+03] 0.45873665302863986\n",
      "69 [5.05250849e-01 5.05250849e-01 2.38498331e+03] 0.6003194527474602\n",
      "test-results 69 [7.86873089e-01 7.86873089e-01 2.69176157e+03] 0.44875760902105577\n",
      "70 [5.05002874e-01 5.05002874e-01 2.38517156e+03] 0.6012337613062397\n",
      "test-results 70 [7.70349015e-01 7.70349015e-01 2.69176157e+03] 0.46851611615607225\n",
      "71 [5.04867408e-01 5.04867408e-01 2.38516853e+03] 0.6012744795011651\n",
      "test-results 71 [7.81723864e-01 7.81723864e-01 2.69176157e+03] 0.4754016565213053\n",
      "72 [5.03639014e-01 5.03639014e-01 2.38497924e+03] 0.6013522142369317\n",
      "test-results 72 [7.62109825e-01 7.62109825e-01 2.69176157e+03] 0.4818880351262349\n",
      "73 [5.04722712e-01 5.04722712e-01 2.38503183e+03] 0.600804369432481\n",
      "test-results 73 [7.92429776e-01 7.92429776e-01 2.69176157e+03] 0.4638259654725077\n",
      "74 [5.04188293e-01 5.04188293e-01 2.38501857e+03] 0.601185639803146\n",
      "test-results 74 [7.88950538e-01 7.88950538e-01 2.69176157e+03] 0.4616305757908392\n",
      "75 [5.02396279e-01 5.02396279e-01 2.38504532e+03] 0.6029624337635272\n",
      "test-results 75 [7.74476930e-01 7.74476930e-01 2.69176157e+03] 0.45694042510727473\n",
      "76 [5.0280243e-01 5.0280243e-01 2.3849242e+03] 0.6018871032520882\n",
      "test-results 76 [7.95283083e-01 7.95283083e-01 2.69176157e+03] 0.4740045903602435\n",
      "77 [5.02393102e-01 5.02393102e-01 2.38505389e+03] 0.6016696310746457\n",
      "test-results 77 [7.88694501e-01 7.88694501e-01 2.69176157e+03] 0.4642251272328111\n",
      "78 [5.01482657e-01 5.01482657e-01 2.38499430e+03] 0.6037962313459769\n",
      "test-results 78 [7.60133967e-01 7.60133967e-01 2.69176157e+03] 0.4735056381598643\n",
      "79 [5.02563685e-01 5.02563685e-01 2.38507289e+03] 0.6027829035404471\n",
      "test-results 79 [7.77594954e-01 7.77594954e-01 2.69176157e+03] 0.4686159065961481\n",
      "80 [5.01037239e-01 5.01037239e-01 2.38502028e+03] 0.60431908998536\n",
      "test-results 80 [7.72808946e-01 7.72808946e-01 2.69176157e+03] 0.46582177427402455\n",
      "81 [5.01461782e-01 5.01461782e-01 2.38510400e+03] 0.6042117420169203\n",
      "test-results 81 [7.81647813e-01 7.81647813e-01 2.69176157e+03] 0.46312743239197685\n",
      "82 [5.00439363e-01 5.00439363e-01 2.38529649e+03] 0.6052731913255438\n",
      "test-results 82 [7.96221308e-01 7.96221308e-01 2.69176157e+03] 0.46681967867478297\n",
      "83 [4.99916784e-01 4.99916784e-01 2.38507824e+03] 0.6056775970342347\n",
      "test-results 83 [7.79929865e-01 7.79929865e-01 2.69176157e+03] 0.474303961680471\n",
      "84 [5.00403859e-01 5.00403859e-01 2.38502410e+03] 0.6042117420169203\n",
      "test-results 84 [7.78485780e-01 7.78485780e-01 2.69176157e+03] 0.45803811994810895\n",
      "85 [4.99906823e-01 4.99906823e-01 2.38503292e+03] 0.6058293648516839\n",
      "test-results 85 [7.70028406e-01 7.70028406e-01 2.69176157e+03] 0.47610018960183614\n",
      "86 [4.99183634e-01 4.99183634e-01 2.38515108e+03] 0.6057072102669078\n",
      "test-results 86 [7.77990554e-01 7.77990554e-01 2.69176157e+03] 0.4576389581878056\n",
      "87 [4.99887000e-01 4.99887000e-01 2.38517078e+03] 0.6053675835046891\n",
      "test-results 87 [7.79278667e-01 7.79278667e-01 2.69176157e+03] 0.4681169543957689\n",
      "88 [4.98810084e-01 4.98810084e-01 2.38497863e+03] 0.6056081910201574\n",
      "test-results 88 [7.81613902e-01 7.81613902e-01 2.69176157e+03] 0.4638259654725077\n",
      "89 [4.98932959e-01 4.98932959e-01 2.38498827e+03] 0.6060061188342011\n",
      "test-results 89 [7.76035309e-01 7.76035309e-01 2.69176157e+03] 0.4745035425606227\n",
      "90 [4.98240291e-01 4.98240291e-01 2.38510403e+03] 0.6058339919192891\n",
      "test-results 90 [8.00565659e-01 8.00565659e-01 2.69176157e+03] 0.4670192595549346\n",
      "91 [4.97952986e-01 4.97952986e-01 2.38512997e+03] 0.6063216848448729\n",
      "test-results 91 [7.77393130e-01 7.77393130e-01 2.69176157e+03] 0.47121045803811995\n",
      "92 [4.97311201e-01 4.97311201e-01 2.38500826e+03] 0.6067547783727159\n",
      "test-results 92 [7.93303772e-01 7.93303772e-01 2.69176157e+03] 0.4559425207065163\n",
      "93 [4.97560167e-01 4.97560167e-01 2.38509083e+03] 0.6067964219811622\n",
      "test-results 93 [7.78788021e-01 7.78788021e-01 2.69176157e+03] 0.4723081528789542\n",
      "94 [4.97801946e-01 4.97801946e-01 2.38500269e+03] 0.6059293095119554\n",
      "test-results 94 [7.83372349e-01 7.83372349e-01 2.69176157e+03] 0.4740045903602435\n",
      "95 [4.97732941e-01 4.97732941e-01 2.38501363e+03] 0.6056701937260665\n",
      "test-results 95 [7.83045361e-01 7.83045361e-01 2.69176157e+03] 0.4749027043209261\n",
      "96 [4.97609970e-01 4.97609970e-01 2.38499435e+03] 0.6067945711541202\n",
      "test-results 96 [8.25134464e-01 8.25134464e-01 2.69176157e+03] 0.45504440674583374\n",
      "97 [4.96816646e-01 4.96816646e-01 2.38513974e+03] 0.608009639107235\n",
      "test-results 97 [7.99180570e-01 7.99180570e-01 2.69176157e+03] 0.4689152779163756\n",
      "98 [4.96339557e-01 4.96339557e-01 2.38501266e+03] 0.6072202613737949\n",
      "test-results 98 [8.05364236e-01 8.05364236e-01 2.69176157e+03] 0.46342680371220435\n",
      "99 [4.95558094e-01 4.95558094e-01 2.38506739e+03] 0.608299293539318\n",
      "test-results 99 [8.06320213e-01 8.06320213e-01 2.69176157e+03] 0.462428899311446\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "# device = 'cpu'\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-3\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "model = MyResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, num_workers=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, num_workers=8, shuffle=False)\n",
    "\n",
    "def criterion(output, targets):\n",
    "    msel = nn.MSELoss()\n",
    "    loss = msel(torch.tanh(output[:,0]),targets[:,0]) , msel(output[:,1],targets[:,1])\n",
    "    return loss\n",
    "\n",
    "def predict(y,target, tau=0.33):\n",
    "    z=y*0\n",
    "    z[y>tau] = 1\n",
    "    z[y<-tau] = -1\n",
    "    return torch.isclose(z,target, atol=1e-4, rtol=1e-4)\n",
    "\n",
    "mloss = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    p = 0\n",
    "    acc_sum = 0\n",
    "    loss_sum=np.array((0.,0.,0.))\n",
    "    for features, targets in train_dataloader:\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        output = model(features)\n",
    "        loss2 = criterion(output, targets)\n",
    "        loss = loss2[0]\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "\n",
    "        loss_sum += np.array((loss.item(),loss2[0].item(),loss2[1].item()))\n",
    "        acc_sum += predict(output[:,0],targets[:,0]).sum().item()\n",
    "        p += 1\n",
    "    print(epoch, loss_sum/p, acc_sum/len(train_ds))\n",
    "    mloss.append(loss_sum/p)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    p = 0\n",
    "    acc_sum = 0\n",
    "    loss_sum=np.array((0.,0.,0.))\n",
    "    with torch.no_grad():\n",
    "        for features, targets in test_dataloader:\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(features)\n",
    "            loss2 = criterion(output, targets)\n",
    "            loss = loss2[0]\n",
    "\n",
    "            loss_sum += np.array((loss.item(),loss2[0].item(),loss2[1].item()))\n",
    "            acc_sum += predict(output[:,0],targets[:,0]).sum().item()\n",
    "            p += 1\n",
    "    print('test-results', epoch, loss_sum/p, acc_sum/len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fcd42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 0., 1., 1.],\n",
       "         [1., 1., 0., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "         [0., 1., 0., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 0., 1., 1., 1., 1., 1.],\n",
       "         [1., 0., 1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 1., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(matrix_to_board(train_ds[76][0]))\n",
    "\n",
    "n  = (train_ds[76][0])\n",
    "print(n.shape)\n",
    "n = torch.round(train_ds[76][0]+7).to(torch.int64)\n",
    "out = torch.zeros(14, 8, 8, dtype=torch.float32)\n",
    "out.scatter_(0, n, 1.0)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54226114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch\n",
    "pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "a = torch.arange(8).unsqueeze(1)\n",
    "b = torch.arange(8).unsqueeze(1)/10\n",
    "x = a.T+b\n",
    "x = x.unsqueeze(0)\n",
    "y = pool(x)\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc11d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyResNet()\n",
    "inp = train_ds[76][0]\n",
    "# display(inp.shape)\n",
    "inp = torch.stack([inp])\n",
    "# inp = torch.cat([inp, inp])\n",
    "# display(inp.shape)\n",
    "# display(inp)\n",
    "output = model(inp)\n",
    "output , train_ds[76][1]\n",
    "\n",
    "a=np.array((1,2,3))\n",
    "a+(1,22,3)\n",
    "\n",
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f808db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(y,target, tau=0.33):\n",
    "    z=y*0\n",
    "    z[y>tau] = 1\n",
    "    z[y<-tau] = -1\n",
    "    return z\n",
    "x=torch.arange(-1,1,0.1)\n",
    "\n",
    "torch.stack([x,predict(x,x)]).T\n",
    "torch.isclose(predict(x,x) ,x*0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
